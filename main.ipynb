{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from DataProcess import *\n",
    "from model import JRNN\n",
    "from torch.optim import SGD,AdamW\n",
    "from criterion import JRNNLoss\n",
    "from runner import Runner\n",
    "# F 范数实现？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "max_len = 30\n",
    "min_len = 3\n",
    "num_examples = -1\n",
    "root = './ace05E/'\n",
    "mode = 'train'\n",
    "entity_type_dim = 20\n",
    "hidden_size = 100\n",
    "num_layers = 2\n",
    "trg_size = 35\n",
    "arg_size = 24\n",
    "num_epoch = 20\n",
    "weight_trg = torch.tensor([0.3]*2 + [1]*33)\n",
    "weight_arg = torch.tensor([0.2]*2 + [1]*22)\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab,entity_vocab,trg_vocab,arg_vocab,embedding_weight = build_vocab(device = device)\n",
    "train_loader = load_data(word_vocab,entity_vocab,trg_vocab,arg_vocab,device,batch_size = batch_size, max_len = max_len ,min_len = min_len,num_examples = num_examples,root = root,mode = mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JRNN(embedding_weight, entity_type_dim, \n",
    "             hidden_size, num_layers, trg_size, arg_size, length = max_len,device=device, dropout = 0.1, bidirectional = True)\n",
    "model = model.double()\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(),lr= 5e-5)\n",
    "loss_fn = JRNNLoss(weight_trg=None,weight_arg=None)\n",
    "loss_fn.to(device)\n",
    "runner = Runner(model,optimizer,loss_fn) \n",
    "runner.train(train_loader, num_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACE05Dataset\n",
    "# 每行为一个字典，包含key如下：\n",
    "# doc_id,sent_id,entity_mentions,relation_mentions,event_mentions,tokens,sentence\n",
    "# 本任务所需内容:\n",
    "# tokens: 列表: 已分词，区分大小写，包括了标点\n",
    "# entity_mentions: [ {'id','start','end','entity_type','mention_type','text'} ]\n",
    "# 经检查: entity_type 包括 {'FAC', 'GPE', 'VEH', 'LOC', 'PER', 'WEA', 'ORG'}, mention_type 只有 'UNK'\n",
    "\n",
    "# event_mentions: [ {'event_type', 'id', 'trigger': {'start', 'end', 'text'}, 'arguments': [{'entity_id', 'text', 'role'}]} ]\n",
    "# 这里的trigger长度都是1，意味着每个event_type都只会对应一个长度为1的触发词\n",
    "# 8-33 subtype: {'Conflict:Attack', 'Justice:Arrest-Jail', 'Transaction:Transfer-Money', 'Life:Marry', 'Life:Injure', 'Business:Merge-Org', 'Business:Start-Org', 'Life:Die', 'Life:Divorce', 'Justice:Release-Parole', 'Personnel:End-Position', 'Justice:Sentence', 'Justice:Pardon', 'Justice:Convict', 'Life:Be-Born', 'Conflict:Demonstrate', 'Contact:Meet', 'Justice:Sue', 'Justice:Charge-Indict', 'Personnel:Start-Position', 'Contact:Phone-Write', 'Justice:Fine', 'Personnel:Nominate', 'Justice:Trial-Hearing', 'Justice:Appeal', 'Justice:Extradite', 'Business:End-Org', 'Justice:Acquit', 'Personnel:Elect', 'Movement:Transport', 'Business:Declare-Bankruptcy', 'Justice:Execute', 'Transaction:Transfer-Ownership'}\n",
    "# 注意: event_mentions 中可能有多个event_type，对应多个事件 应该作为 label处理\n",
    "# role: 'Person', 'Prosecutor', 'Recipient', 'Attacker', 'Artifact', 'Origin', 'Entity', 'Vehicle', 'Place', 'Seller', 'Agent', 'Defendant', 'Buyer', 'Giver', 'Beneficiary', 'Victim', 'Adjudicator', 'Target', 'Instrument', 'Org', 'Destination', 'Plaintiff'\n",
    "class ACE05EDataset(Dataset):\n",
    "    def __init__(self, root = './ace05E/', mode = 'train') -> None:\n",
    "        super().__init__()\n",
    "        data = pd.read_json(root + mode + '.oneie.json', lines=True)\n",
    "        self.data = data.to_dict(orient='records')\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CNN_CF_20030303.1900.00']\n",
      "['STORY']\n",
      "['2003', '-', '03', '-', '03T19:00:00', '-', '05:00']\n",
      "['New', 'Questions', 'About', 'Attacking', 'Iraq', ';', 'Is', 'Torturing', 'Terrorists', 'Necessary', '?']\n",
      "['BEGALA', 'Well', ',', 'we', \"'ll\", 'debate', 'that', 'later', 'on', 'in', 'the', 'show', '.']\n",
      "['We', \"'ll\", 'have', 'a', 'couple', 'of', 'experts', 'come', 'out', ',', 'so', 'I', \"'ll\", 'withhold', 'my', 'comments', 'until', 'then', '.']\n",
      "['Even', 'as', 'the', 'secretary', 'of', 'homeland', 'security', 'was', 'putting', 'his', 'people', 'on', 'high', 'alert', 'last', 'month', ',', 'a', '30-foot', 'Cuban', 'patrol', 'boat', 'with', 'four', 'heavily', 'armed', 'men', 'landed', 'on', 'American', 'shores', ',', 'utterly', 'undetected', 'by', 'the', 'Coast', 'Guard', 'Secretary', 'Ridge', 'now', 'leads', '.']\n",
      "['Now', ',', 'why', 'has', 'our', 'president', 'placed', 'homeland', 'security', 'in', 'the', 'hands', 'of', 'Republican', 'political', 'hacks', 'instead', 'of', 'professionals', ',', 'by', 'the', 'way', '?', 'Attorney', 'General', 'John', 'Ashcroft', ',', 'for', 'example', ',', 'is', 'a', 'career', 'politician', '.']\n",
      "['He', 'lost', 'an', 'election', 'to', 'a', 'dead', 'man', '.']\n",
      "['Secretary', 'of', 'Homeland', 'Security', 'Tom', 'Ridge', 'is', 'another', 'career', 'politician', 'who', 'was', 'passed', 'over', 'by', 'Mr.', 'Bush', 'for', 'the', 'vice', 'presidency', '.']\n",
      "['And', 'Deputy', 'Secretary', 'of', 'Homeland', 'Security', 'Asa', 'Hutchinson', 'is', 'yet', 'another', 'career', 'politician', 'and', 'a', 'graduate', 'of', 'the', 'disgraceful', 'Bob', 'Jones', 'University', '.']\n",
      "['Apparently', ',', 'Mr.', 'Bush', 'only', 'turns', 'to', 'professionals', 'when', 'it', \"'s\", 'really', 'important', ',', 'like', 'political', 'consulting', '.']\n",
      "['NOVAK', 'Paul', ',', 'as', 'I', 'understand', 'your', 'definition', 'of', 'a', 'political', '--', 'of', 'a', 'professional', 'politician', 'based', 'on', 'that', 'is', 'somebody', 'who', 'is', 'elected', 'to', 'public', 'office', '.']\n",
      "['Now', 'in', 'your', 'administration', ',', 'the', 'Clinton', 'administration', ',', 'there', 'were', 'these', 'members', 'of', 'the', 'cabinet', 'who', 'by', 'your', 'definition', 'were', 'professional', 'politicians', '--', 'Lloyd', 'Bentsen', ',', 'Les', 'Aspin', ',', 'William', 'S.', 'Cohen', ',', 'Janet', 'Reno', ',', 'Bruce', 'Babbitt', ',', 'Mike', 'Espy', ',', 'Dan', 'Glickman', ',', 'Norman', 'Mineta', ',', 'Henry', 'Cisneros', ',', 'Federico', 'Pena', ',', 'Bill', 'Richardson', ',', 'Richard', 'Riley', ',', '12', 'of', 'them', ',', 'not', 'to', 'mention', 'former', 'Democratic', 'National', 'Chairman', 'Ron', 'Brown', ',', 'and', 'one', 'of', 'the', 'great', 'professional', 'politicians', 'of', 'all', 'time', ',', 'Bill', 'Daly', '.']\n",
      "['BEGALA', 'And', 'you', 'know', 'what', ',', 'they', 'did', 'a', 'hell', 'of', 'a', 'job', 'for', 'our', 'country', '.']\n",
      "['And', 'these', 'bozos', 'let', 'four', 'armed', 'Cubans', 'land', 'on', 'our', 'shores', 'when', 'they', \"'re\", 'trying', 'to', 'make', 'a', 'high', 'terrorist', 'alert', '.']\n",
      "['Our', 'president', 'has', 'put', 'homeland', 'security', 'in', 'the', 'hands', 'of', 'failed', 'Republican', 'hacks', '.']\n",
      "['Hire', 'professionals', ',', 'Mr.', 'President', '.']\n",
      "['NOVAK', 'So', 'it', \"'s\", 'OK', '--', 'it', \"'s\", 'OK', 'to', 'have', 'professional', 'politicians', 'at', 'the', 'Justice', 'Department', 'and', 'the', 'Pentagon', '...']\n",
      "['BEGALA', 'Janet', 'Reno', 'was', 'a', 'career', 'prosecutor', '.']\n"
     ]
    }
   ],
   "source": [
    "trainset = ACE05EDataset()\n",
    "# print(len(trainset))\n",
    "# entity_type = set()\n",
    "# mention_type = set()\n",
    "# for i in range(len(trainset)):\n",
    "#     entity_mention = trainset[i]['entity_mentions']\n",
    "#     for item in entity_mention:\n",
    "#         entity_type.add(item['entity_type'])\n",
    "#         mention_type.add(item['mention_type'])\n",
    "# print(entity_type)\n",
    "# print(mention_type)\n",
    "\n",
    "# for idx in range(len(trainset)):\n",
    "#     print('-------------------')\n",
    "#     event_mention = trainset[idx]['event_mentions']\n",
    "#     entity_type = trainset[idx]['entity_mentions']\n",
    "#     for item in entity_type:\n",
    "#         print(item['id'],item['text'],end='\\t')\n",
    "#     print()\n",
    "#     for event in event_mention:\n",
    "#         print(event['arguments'])\n",
    "# argset = set()\n",
    "# for i in range(len(trainset)):\n",
    "#     event_mention = trainset[i]['event_mentions']\n",
    "#     for item in event_mention:\n",
    "#         arguments = item['arguments']\n",
    "#         for arg in arguments:\n",
    "#             argset.add(arg['role'])\n",
    "# print(argset)\n",
    "# event_type = set()\n",
    "# for i in range(len(trainset)):\n",
    "#     event_mention = trainset[i]['event_mentions']\n",
    "#     for item in event_mention:\n",
    "#         event_type.add(item['event_type'])\n",
    "# print(event_type)\n",
    "# print(len(event_type))\n",
    "\n",
    "for i in range(20):\n",
    "    print(trainset[i]['tokens'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
